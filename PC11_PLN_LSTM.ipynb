{"cells":[{"cell_type":"markdown","metadata":{"id":"xMsNyA3WPrER"},"source":["##**Notebook PC#11**\n","\n","## Encoder-Decoder LSTM for Natural Language Processing.\n","\n","**Professor:** Fernando J. Von Zuben <br>\n","**Aluno(a):** Gabriel Toffanetto França da Rocha - 289320<br>\n","**Aluno(a):** Maria Fernanda Paulino Gomes - 206745<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xumdIFHDdrn"},"outputs":[],"source":["from random import seed\n","from random import randint\n","from numpy import array\n","from numpy import argmax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fspvFmS6Ddro"},"outputs":[],"source":["def random_sum_pairs(n_examples, n_numbers, largest):\n","    X,y = list(), list()\n","    for i in range(n_examples):\n","        in_pattern=[randint(1,largest) for _ in range(n_numbers)]\n","        out_pattern = sum(in_pattern)\n","        X.append(in_pattern)\n","        y.append(out_pattern)\n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzr9HXh8Ddrp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425149263,"user_tz":180,"elapsed":5,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"9c9447f4-a06f-4878-9665-b5f541543877"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3, 10]] [13]\n"]}],"source":["seed(1)\n","n_samples =1\n","n_numbers = 2\n","largest = 10\n","X,y = random_sum_pairs(n_samples, n_numbers, largest)\n","print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QWTgrmmuDdrp"},"outputs":[],"source":["from math import ceil\n","from math import log10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbBlwQTvDdrp"},"outputs":[],"source":["def to_string(X,y,n_numbers,largest):\n","    max_length = n_numbers*ceil(log10(largest+1)) + n_numbers - 1\n","    Xstr = list()\n","    for pattern in X:\n","        strp = '+'.join([str(n) for n in pattern])\n","        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n","        Xstr.append(strp)\n","    maxlength = ceil(log10(n_numbers*(largest+1)))\n","    ystr = list()\n","    for pattern in y:\n","        strp = str(pattern)\n","        strp = ''.join([' 'for _ in range(maxlength-len(strp))]) + strp\n","        ystr.append(strp)\n","    return Xstr, ystr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAVqEpSsDdrq"},"outputs":[],"source":["seed(1)\n","n_samples = 1\n","n_numbers = 2\n","largest = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-m3UD5uDdrq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425162083,"user_tz":180,"elapsed":479,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"b65e98b3-2f37-4baa-855d-67967df42cf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[3, 10]] [13]\n","[' 3+10'] ['13']\n"]}],"source":["X,y = random_sum_pairs(n_samples, n_numbers, largest)\n","print(X,y)\n","\n","X,y = to_string(X,y,n_numbers,largest)\n","print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwQXLtpfDdrq"},"outputs":[],"source":["alphabet = ['0','1','2','3','4','5','6','7','8','9','+',' ']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXKcXm8JDdrq"},"outputs":[],"source":["def integer_encode(X,y,alphabet):\n","    char_to_int = dict((c,i) for i,c in enumerate(alphabet))\n","    Xenc = list()\n","    for pattern in X:\n","        integer_encoded = [char_to_int[char] for char in pattern]\n","        Xenc.append(integer_encoded)\n","    yenc = list()\n","    for pattern in y:\n","        integer_encoded = [char_to_int[char] for char in pattern]\n","        yenc.append(integer_encoded)\n","    return Xenc, yenc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjD9y1M2Ddrr"},"outputs":[],"source":["X,y = integer_encode(X,y,alphabet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v02pwsYYDdrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425931326,"user_tz":180,"elapsed":678,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"800e365b-8eaa-4de0-e8a9-289fd0fd5824"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[11, 3, 10, 1, 0]] [[1, 3]]\n"]}],"source":["print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vad64QkqDdrr"},"outputs":[],"source":["def one_hot_encode(X,y,max_int):\n","    Xenc = list()\n","    for seq in X:\n","        pattern = list()\n","        for index in seq:\n","            vector = [0 for _ in range(max_int)]\n","            vector[index] = 1\n","            pattern.append(vector)\n","        Xenc.append(pattern)\n","\n","    yenc = list()\n","    for seq in y:\n","        pattern = list()\n","        for index in seq:\n","            vector = [0 for _ in range(max_int)]\n","            vector[index] = 1\n","            pattern.append(vector)\n","        yenc.append(pattern)\n","    return Xenc, yenc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_tCfgMPDdrr"},"outputs":[],"source":["X,y = one_hot_encode(X,y,len(alphabet))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7VdCFIgDdrr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425946507,"user_tz":180,"elapsed":258,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"bff12103-06cc-40f0-efdb-2c5975ed165d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n"]}],"source":["print(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVdn4BqyDdrs"},"outputs":[],"source":["def generate_data(n_samples,n_numbers, largest, alphabet):\n","    X,y = random_sum_pairs(n_samples,n_numbers,largest)\n","    X,y = to_string(X,y,n_numbers,largest)\n","    X,y = integer_encode(X,y,alphabet)\n","    X,y = one_hot_encode(X,y,len(alphabet))\n","    X,y = array(X), array(y)\n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RDp9JqNkDdrs"},"outputs":[],"source":["def invert(seq,alphabet):\n","    int_to_char = dict((i,c) for i,c in enumerate(alphabet))\n","    strings  = list()\n","    for pattern in seq:\n","        string = int_to_char[argmax(pattern)]\n","        strings.append(string)\n","    return ''.join(strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BqRNPCkDdrs"},"outputs":[],"source":["n_terms = 3\n","largest = 10\n","alphabet = [str(x) for x in range(10)] + ['+', ' ']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PijAMEFxDdrs"},"outputs":[],"source":["n_chars = len(alphabet)\n","n_in_seq_length = n_terms*ceil(log10(largest+1)) +n_terms-1\n","n_out_seq_length = ceil(log10(n_terms*(largest+1)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RR9pPe1oDdrs"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import RepeatVector\n","from keras.layers import TimeDistributed\n","from keras.layers import Dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gxs5FSIwDdrs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717425973491,"user_tz":180,"elapsed":1410,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"813b3377-863c-49ef-fe0b-fe43e1590125"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 75)                26400     \n","                                                                 \n"," repeat_vector (RepeatVecto  (None, 2, 75)             0         \n"," r)                                                              \n","                                                                 \n"," lstm_1 (LSTM)               (None, 2, 50)             25200     \n","                                                                 \n"," time_distributed (TimeDist  (None, 2, 12)             612       \n"," ributed)                                                        \n","                                                                 \n","=================================================================\n","Total params: 52212 (203.95 KB)\n","Trainable params: 52212 (203.95 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["model = Sequential()\n","model.add(LSTM(75, input_shape=(n_in_seq_length,n_chars)))\n","model.add(RepeatVector(n_out_seq_length))\n","model.add(LSTM(50,return_sequences=True))\n","model.add(TimeDistributed(Dense(n_chars,activation='softmax')))\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vG1QwiwFDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717426045141,"user_tz":180,"elapsed":66356,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"1986744b-26a5-45d0-92c8-ba529e51f0c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["7500/7500 [==============================] - 61s 8ms/step - loss: 0.4006 - accuracy: 0.8773\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7c60a2a91e10>"]},"metadata":{},"execution_count":23}],"source":["X,y = generate_data(75000,n_terms,largest,alphabet)\n","model.fit(X,y,epochs=1,batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBWMp85oDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717426053648,"user_tz":180,"elapsed":2236,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"fa771130-ba6d-4697-cb52-2d56a102638f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.029399, Accuracy: 99.500000\n"]}],"source":["X,y = generate_data(100,n_terms,largest,alphabet)\n","loss,acc = model.evaluate(X,y,verbose=0)\n","print('Loss: %f, Accuracy: %f' %(loss,acc*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjorRbDxDdrt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717426066892,"user_tz":180,"elapsed":2017,"user":{"displayName":"Maria Fernanda Paulino Gomes","userId":"13782244049113521843"}},"outputId":"ce255d61-69e6-4780-87d2-61a18b174a21"},"outputs":[{"output_type":"stream","name":"stdout","text":["   3+7+5 = 15 (expect 15)\n","  2+10+6 = 18 (expect 18)\n","   4+5+9 = 18 (expect 18)\n","   2+2+4 =  8 (expect  8)\n"," 10+7+10 = 27 (expect 27)\n","  10+2+3 = 15 (expect 15)\n","   8+4+1 = 13 (expect 13)\n","   8+1+3 = 12 (expect 12)\n","   5+9+6 = 20 (expect 20)\n","   1+5+8 = 14 (expect 14)\n"]}],"source":["for _ in range(10):\n","    X,y = generate_data(1,n_terms,largest,alphabet)\n","    yhat = model.predict(X,verbose=0)\n","    in_seq = invert(X[0],alphabet)\n","    out_seq = invert(y[0],alphabet)\n","    predicted = invert(yhat[0],alphabet)\n","    print('%s = %s (expect %s)' %(in_seq,predicted,out_seq))"]},{"cell_type":"markdown","source":["<font color=\"green\">\n","Atividade (a) <br>\n","Como são gerados os dados de treinamento?\n","</font>"],"metadata":{"id":"mulXq9ZZKkX5"}},{"cell_type":"markdown","source":["**Resposta:** A função *generate_data* gera os dados de treinamento, realizando uma série de transformações nos dados.\n","\n","A função é dada pelo seguinte código:\n","\n","```\n","def generate_data(n_samples,n_numbers, largest, alphabet):\n","    X,y = random_sum_pairs(n_samples,n_numbers,largest)\n","    X,y = to_string(X,y,n_numbers,largest)\n","    X,y = integer_encode(X,y,alphabet)\n","    X,y = one_hot_encode(X,y,len(alphabet))\n","    X,y = array(X), array(y)\n","    return X,y\n","```\n","\n","Tem-se que a função *random_sum_pairs* gera pares de números aleatórios com base nos parâmetros de entrada: *n_examples* (número de exemplos de pares entrada-saída a serem gerados), *n_numbers* (número de inteiros em cada lista de entrada), *largest* (maior valor que cada inteiro de entrada X pode assumir).\n","\n","A função *to_string* converte os números gerados para *strings*. A função *integer_encode* utiliza um alfabeto de símbolos para codificar as *strings* de entrada (x) e a saída esperada (y), essa função converte cada símbolo de acordo com a posição de índices da lista *alphabet*.\n","\n","A função *one_hot_encode* converte a saída numérica para uma representação binária única (*one-hot encoding*), onde cada símbolo é visto como uma classe separada, evitando falsas interpretações pela rede neural.\n","\n","Por fim, a última linha da função *generate_data* garante que tanto x quanto y estejam em formato de *array* antes de serem retornados.\n","\n","\n","Dessa forma, os dados de treinamento são gerados, a partir da geração de pares de números e duas somas esperadas, dessa forma, combinando o alfabeto e gerando operações obtém-se \"frases\" para que o modelo aprenda a manipular esses símbolos durante treinamento, realizando corretamente as operações matemáticas de forma semântica, e não algébrica. Durante o processo, são realizadas conversões intermediárias (como *integer_encode*) para preparar os dados no formato *one-hot encoding* que é o formato mais adequado de representar o alfabeto para o aprendizado de redes neurais.\n","\n"],"metadata":{"id":"BGsvW_2eTpfB"}},{"cell_type":"markdown","source":["<font color=\"green\">\n","Atividade (b) <br>\n","Como uma calculadora simples pode operar baseada no conceito de tradução de frases, ou seja, sem realizar operações algébricas?\n","</font>"],"metadata":{"id":"Fn1TbpOT_ew-"}},{"cell_type":"markdown","source":["**Resposta:** Uma calculadora simples, baseada no conceito de tradução de frases opera transformando expressões matemáticas em suas respectivas soluluções sem realizar operações algébricas diretamente. O modelo de tradução de sequência para sequência (*seq2seq*) é usado para mapear uma expressão matemática.\n","\n","O modelo trata a expressão de entrada como uma sequência de símbolos e aprende a prever a sequência correta de saída. Este processo pode ser dividido da seguinte forma:\n","\n","*   Codificação de Entrada: a expressão matemática a ser mapeada é *tokenizada* e convertida em uma sequência de vetores *one-hot encoded*. Uma camada LSTM processa essa sequência codificando a informação em um vetor de comprimento fixo que captura o contexto da expressão;\n","*   Vetor de Contexto: o vetor de contexto gerado pela LSTM, captura as informações essenciais da sequência de entrada;\n","*   Decodificação para a Saída: uma camada *ReapeatVector* repeto o vetor de contexto para que ele corresponda ao comprimento da sequência de saída esperada. Uma segunda camada LSTM decodifica esse vetor repetido para gerar a sequência de saída passo a passo. Cada símbolo da sequência de saída é gerado um por vez, até que a expressão completa seja traduzida.\n","*   Camada *Time Distributed*: aplicada uma camada densa a cada elemento da sequência de saída para produzir a saída final, transformando os vetores intermediários em símbolos compreensíveis.\n","*  Função *Softmax* e Função de Perda: Entropia Cruzada: a camada *softmax* transforma a saída da rede em probabilidades, já a função de perda mede a diferença entre a distribuição de probabilidade prevista e a distribuição verdadeira (a saída correta codificada como *one-hot*).\n","\n","\n","Durante o processo de treinamento, o modelo aprende a reconhecer padrões nas sequências de entrada e saída. Cada iteração ajusta os pesos da rede para minimizar a perda da entropia cruzada. A camada *RepeatVector* assegura que o vetor de contexto seja adequadamente utilizado pelo decodificador. Com o tempo, o modelo tende a melhorar a capacidade de traduzir expressões matemáticas em suas respectivas soluções, tornando-se então, uma calculadora eficiente.\n","\n","Em suma, o modelo não realiza operações algébricas diretamente, mas mapeia espressões matemáticas para suas soluções através de um processo de aprendizado baseado em *seq2seq*. Ele transforma a entrada em uma representação vetorial, utilizando LSTMs para codificar e decodificar essa representação, e aplica técnicas de *machine learning* para ajustar melhor suas previsões.\n","\n","Pode-se correlacionar tal solução para a calculadora com a Sala Chinesa de Searle. Com as entradas em texto, onde se tem os números e sinais matemáticos como caracteres de um alfabeto, a rede neural aprende a combiná-los de acordo com o contexto para entregrar o resultado correto da operação matemática, porém, sem resolver a expressão propriamente dita, ou seja, a calculadora não realiza as operações algébricas, mas age como estivesse.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"8xRF9vul_ew_"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}